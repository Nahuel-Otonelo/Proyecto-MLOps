# MLOps Final Project - Social Network Ads Pipeline

Este proyecto implementa un pipeline de **MLOps end-to-end** para la predicciÃ³n de compras de usuarios basadas en publicidad en redes sociales. El sistema estÃ¡ completamente contenerizado utilizando **Docker** y orquesta el ciclo de vida del machine learning desde la ingesta de datos hasta el registro del modelo.

## ğŸ—ï¸ Arquitectura del Proyecto

El entorno simula una infraestructura productiva real utilizando los siguientes servicios:

* **Apache Airflow:** Orquestador de flujos de trabajo (DAGs).
* **MinIO:** Data Lake (Object Storage compatible con S3) para almacenar datasets y artefactos.
* **MLflow:** Tracking server para el registro de experimentos, mÃ©tricas y modelos.
* **PostgreSQL & Redis:** Backend y Broker para los servicios de orquestaciÃ³n.
* **Docker Compose:** GestiÃ³n de infraestructura como cÃ³digo.

---

## ğŸš€ Quick Start 

Este proyecto estÃ¡ configurado para desplegarse automÃ¡ticamente con un solo comando, incluyendo la instalaciÃ³n de librerÃ­as y la carga del dataset.

### Prerrequisitos
* Docker Desktop instalado y corriendo.

### EjecuciÃ³n
1.  Clonar el repositorio.
2.  Ejecutar el siguiente comando en la raÃ­z del proyecto:

```bash
docker compose --profile all up -d --build
```

Esperar unos minutos a que los servicios indiquen estado healthy.

Acceso a los Servicios
Servicio	URL	Credenciales (User/Pass)
Airflow	http://localhost:8080	airflow / airflow
MinIO	http://localhost:9091	minio / minio123
MLflow	http://localhost:5001	N/A



## âš™ï¸ Flujo de Trabajo (Pipeline)
El DAG mlops_final_project automatiza los siguientes pasos:

1. AutomatizaciÃ³n de Infraestructura (docker-compose)
Se construye una imagen de Airflow personalizada inyectando el archivo requirements.txt.

Un contenedor efÃ­mero (create_s3_buckets) inicializa los buckets en MinIO y carga automÃ¡ticamente el dataset Social_Network_Ads.csv.

2. PreparaciÃ³n de Datos (src/data_prep.py)
Ingesta: Lee el archivo crudo desde MinIO.

Limpieza: Elimina identificadores irrelevantes (User ID) y codifica variables categÃ³ricas (Gender).

Split: Divide el dataset en entrenamiento (80%) y prueba (20%).

Feature Scaling: Aplica StandardScaler solo a variables numÃ©ricas para evitar data leakage.

Artefactos: Guarda el objeto scaler.joblib en MinIO para su uso posterior en inferencia y los datasets procesados (train_scaled.csv, test_scaled.csv).

## 3. Entrenamiento y SelecciÃ³n (src/train.py)
Entrena mÃºltiples modelos candidatos:

RegresiÃ³n LogÃ­stica.

Naive Bayes (Gaussian).

EvalÃºa el rendimiento utilizando mÃ©tricas de Accuracy y F1-Score.

Utiliza MLflow para registrar parÃ¡metros, mÃ©tricas y el modelo serializado.

Selecciona automÃ¡ticamente el mejor modelo y lo promueve.

El modelo ganador queda registrado en MLflow listo para ser consumido.

## ğŸš§ PrÃ³ximos Pasos (Roadmap)
El avance actual cubre la infraestructura, orquestaciÃ³n y entrenamiento. Para completar el ciclo de vida de MLOps productivo, los siguientes pasos estÃ¡n pendientes de implementaciÃ³n:

Despliegue de API (Serving):

Implementar el servicio con FastAPI (dockerfiles/fastapi/app.py).

Configurar el contenedor para descargar automÃ¡ticamente el modelo "Champion" desde MLflow y el scaler desde MinIO al iniciarse.

Exponer el endpoint POST /predict para recibir datos de nuevos usuarios.

Monitoreo:

Implementar logs de predicciÃ³n para detectar Data Drift en el futuro.

ğŸ“‚ Estructura del Repositorio
Plaintext
```
.
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ pipeline.py      # DefiniciÃ³n del DAG de Airflow
â”œâ”€â”€ dockerfiles/             # Definiciones de imÃ¡genes Docker
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py         # LÃ³gica de ETL y preprocesamiento
â”‚   â””â”€â”€ train.py             # LÃ³gica de entrenamiento y MLflow
â”œâ”€â”€ Social_Network_Ads.csv   # Dataset original
â”œâ”€â”€ docker-compose.yaml      # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt         # Dependencias de Python
â””â”€â”€ README.md                # DocumentaciÃ³n del proyecto
```